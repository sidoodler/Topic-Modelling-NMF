{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Topic_coherence_calculator.ipynb","provenance":[],"mount_file_id":"1QwRMlTLwo46EDjz5s9LB2ppa5mOiIJrN","authorship_tag":"ABX9TyO/jgri7/dnoqnVv5HOSexs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bUKVdSlw5DaE"},"source":["# Topic Coherence Score calcutaion"]},{"cell_type":"code","metadata":{"id":"pJ2ZWDri5YQp"},"source":["#Loading the data matrix (not uploaded with the submission as it was very big ~18GB)\n","import pickle5 as pickle\n","with open('data_matrix.pkl', 'rb') as f:\n","    V = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgnQyBdrvcBY"},"source":["#Loading the vocabulary of our dataset\n","import pickle5 as pickle\n","with open('vocab.pkl', 'rb') as f:\n","    vocab = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQNkUl9jvyjZ"},"source":["#Loading the pretrained word vector model on our dataset\n","from gensim.models import Word2Vec\n","w2v_model = Word2Vec.load(\"word2vec.model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QW9m_nC-taac"},"source":["from sklearn import decomposition\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Function to return top k words in a topic. \n","def word (topic, vocabulary, k):\n","  vocabulary = list(vocabulary[0])\n","  word_list = []\n","  for i in range(k):\n","     word_list.append(vocabulary[topic.index(max(topic))])\n","     topic[topic.index(max(topic))] = 0.0\n","  return word_list\n","\n","# Function to calculate the coherence score for a decomposition, given a topic matrix.\n","def calculate_coherence(w2v_model, topic_matrix, num_tops, vocabulary ):\n","    \n","    overall_topic_coherence = []\n","    topic_coherence_score = []\n","    for i in range(num_tops):\n","      topic = list (topic_matrix[i])\n","      topic_words = word(topic, vocabulary, 10)\n","      for j in range(len(topic_words)):\n","        for k in range(j+1,len(topic_words)):\n","          try:\n","            topic_coherence_score.append(w2v_model.similarity(topic_words[j], topic_words[k] ))  # For every pair of top words calculate the similarity score \n","          except:\n","            continue\n","      overall_topic_coherence.append(sum(topic_coherence_score)/len(topic_coherence_score)) #Storing Average similarity score for a topic in the topic matrix\n","\n","    return sum(overall_topic_coherence)/len(overall_topic_coherence) #returning the average score over the topic matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QajvDdOQ4ZVB"},"source":["# Code to find best number of topics to decompose into according to the  coherence score."]},{"cell_type":"code","metadata":{"id":"JHATalgc4U22"},"source":["topic_models = []\n","kmin = 3\n","kmax = 24\n","\n","#Storing the decomposition for every number of topic in range kmin to kmax\n","for k in range(kmin,kmax+1):\n","    print(\"Applying NMF for k=%d ...\" % k )\n","    model = decomposition.NMF( n_components=k, random_state=1 ) \n","    W = model.fit_transform(V)\n","    H = model.components_    \n","    topic_models.append( (k,W,H) ) \n","\n","\n","# Calculating the topic coherence for each topic decomposition in range kmin to kmax \n","k_values = []\n","coherences = []\n","for (k,W,H) in topic_models:\n","    k_values.append( k )\n","    coherences.append( calculate_coherence( w2v_model, H.transpose(), k, vocab ) )\n","    print(\"K=%02d: Coherence=%.4f\" % ( k, coherences[-1] ) )\n","\n","%matplotlib inline\n","plt.style.use(\"ggplot\")\n","matplotlib.rcParams.update({\"font.size\": 14})\n","\n","fig = plt.figure(figsize=(13,7))\n","ax = plt.plot( k_values, coherences )\n","plt.xticks(k_values)\n","plt.xlabel(\"Number of Topics\")\n","plt.ylabel(\"Topic matrix Coherence\")\n","plt.scatter( k_values, coherences, s=120)\n","ymax = max(coherences)\n","xpos = coherences.index(ymax)\n","best_k = k_values[xpos]\n","plt.annotate( \"k=%d\" % best_k, xy=(best_k, ymax), xytext=(best_k, ymax), textcoords=\"offset points\", fontsize=16)\n","plt.show()"],"execution_count":null,"outputs":[]}]}